{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arulrajgopal-zerotoone/zero_to_one_spark/blob/main/apache_spark/05_schema_control.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4b57a6cc-ccd4-4bd1-831b-5483d510fa0c",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h0a2D3UWdzf",
        "outputId": "fb5d3fdb-26bb-4191-9530-ff4136c7f04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=cb10e2a141445b311ea1f36bfbc215c9166f5da30b2a36215434fbf357d08c74\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#create spark session\n",
        "spark= SparkSession.builder.appName('mysparksession').getOrCreate()\n",
        "\n",
        "#create spark context\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read a file with inferschema"
      ],
      "metadata": {
        "id": "T8ureqnKAngk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "21543520-36f7-4237-9f83-8a708e2507d9",
          "showTitle": false,
          "title": ""
        },
        "id": "GdJ8bKrF__oZ"
      },
      "outputs": [],
      "source": [
        "user_sch_inf_df = spark.read\\\n",
        "    .format(\"csv\")\\\n",
        "    .option('Header',False)\\\n",
        "    .option('InferSchema',True)\\\n",
        "    .option('sep','|')\\\n",
        "    .load('user.user')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "29e4eed5-ce06-4ea9-b3a6-0c2905ba4c39",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd944z21BYNg",
        "outputId": "481d1e13-1a90-490b-a570-2677785a4f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- _c1: integer (nullable = true)\n",
            " |-- _c2: string (nullable = true)\n",
            " |-- _c3: string (nullable = true)\n",
            " |-- _c4: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_sch_inf_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read a file without schema"
      ],
      "metadata": {
        "id": "paq-pQ_mBJs9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "957116cb-62e9-4d9e-a9b7-2022cee64ac5",
          "showTitle": false,
          "title": ""
        },
        "id": "Epp5QtVMKd-8"
      },
      "outputs": [],
      "source": [
        "user_df = spark.read\\\n",
        "    .format(\"csv\")\\\n",
        "    .option('Header',False)\\\n",
        "    .option('sep','|')\\\n",
        "    .load('user.user')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4299838a-885c-4738-b38b-b71bb622063a",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50qsivMTLp4n",
        "outputId": "0b67385b-4b55-4a8e-d56a-72cdac6757ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            " |-- _c2: string (nullable = true)\n",
            " |-- _c3: string (nullable = true)\n",
            " |-- _c4: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#column renaming"
      ],
      "metadata": {
        "id": "1vl5VynEDmis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL0lblkCEuAh",
        "outputId": "69304415-9c01-4f0d-88be-9ca6b4949cfc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+----------+-----+\n",
            "|_c0|_c1|_c2|       _c3|  _c4|\n",
            "+---+---+---+----------+-----+\n",
            "|  1| 24|  M|technician|85711|\n",
            "|  2| 53|  F|     other|94043|\n",
            "|  3| 23|  M|    writer|32067|\n",
            "+---+---+---+----------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_mapping = {\n",
        "    '_c0':'user_id',\n",
        "    '_c1':'age',\n",
        "    '_c2':'gender',\n",
        "    '_c3':'occupation',\n",
        "    '_c4':'zip_code'\n",
        "    }"
      ],
      "metadata": {
        "id": "NHjislNQDpcC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def col_renaming(df, col_map):\n",
        "  list = []\n",
        "  for i, j in col_map.items():\n",
        "    list.append(f\"{i} as {j}\")\n",
        "\n",
        "  renamed_df = df.selectExpr(*list)\n",
        "\n",
        "  return renamed_df"
      ],
      "metadata": {
        "id": "ndnk_ZIzEBTU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_renamed_df = col_renaming(user_df, col_mapping)\n",
        "col_renamed_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMWX64cGDh21",
        "outputId": "9346b67c-a92a-48fb-bfed-d554cfeedb2e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+------+-------------+--------+\n",
            "|user_id|age|gender|   occupation|zip_code|\n",
            "+-------+---+------+-------------+--------+\n",
            "|      1| 24|     M|   technician|   85711|\n",
            "|      2| 53|     F|        other|   94043|\n",
            "|      3| 23|     M|       writer|   32067|\n",
            "|      4| 24|     M|   technician|   43537|\n",
            "|      5| 33|     F|        other|   15213|\n",
            "|      6| 42|     M|    executive|   98101|\n",
            "|      7| 57|     M|administrator|   91344|\n",
            "|      8| 36|     M|administrator|   05201|\n",
            "|      9| 29|     M|      student|   01002|\n",
            "|     10| 53|     M|       lawyer|   90703|\n",
            "|     11| 39|     F|        other|   30329|\n",
            "|     12| 28|     F|        other|   06405|\n",
            "|     13| 47|     M|     educator|   29206|\n",
            "|     14| 45|     M|    scientist|   55106|\n",
            "|     15| 49|     F|     educator|   97301|\n",
            "|     16| 21|     M|entertainment|   10309|\n",
            "|     17| 30|     M|   programmer|   06355|\n",
            "|     18| 35|     F|        other|   37212|\n",
            "|     19| 40|     M|    librarian|   02138|\n",
            "|     20| 42|     F|    homemaker|   95660|\n",
            "+-------+---+------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#apply schema"
      ],
      "metadata": {
        "id": "SAvetaqzDb2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3f53a914-4684-4af0-ba20-597ab898e0ab",
          "showTitle": false,
          "title": ""
        },
        "id": "iE75ChuCARa_"
      },
      "outputs": [],
      "source": [
        "schema = {\n",
        "'user_id': 'INT',\n",
        " 'age':'INT',\n",
        " 'gender':'STRING',\n",
        " 'occupation':'STRING',\n",
        " 'zip_code':'INT'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def date_type_conversion(df, schema):\n",
        "  column_list = []\n",
        "  for column, datatype in schema.items():\n",
        "      column_list.append(f\"cast({column} as {datatype}) {column}\")\n",
        "      data_type_converted_df = df.selectExpr(column_list)\n",
        "\n",
        "  return data_type_converted_df"
      ],
      "metadata": {
        "id": "JvCJ1oR2GEcB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_type_converted_df = date_type_conversion(col_renamed_df, schema)\n",
        "col_renamed_df.printSchema()\n",
        "data_type_converted_df.printSchema()"
      ],
      "metadata": {
        "id": "XZrVwe9eGPpg",
        "outputId": "3ce96732-288f-44aa-ac76-aea3750973dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- zip_code: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- zip_code: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#apply schema using structtype"
      ],
      "metadata": {
        "id": "Puu9I8avGXmX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "be497837-6292-4527-94fd-1feff828553d",
          "showTitle": false,
          "title": ""
        },
        "id": "e7NRh47wUnp6"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "bf677221-c258-4c8a-88e7-d8fd3b3169ca",
          "showTitle": false,
          "title": ""
        },
        "id": "-DSJgtzYUnV1"
      },
      "outputs": [],
      "source": [
        "dataDF = [('james','1991-04-01','M',3000),\n",
        "  ('Michel','2000-05-19','M',4000),\n",
        "  ('Robert','1978-09-05','M',4000),\n",
        "  ('Maria','1967-12-01','F',4000),\n",
        "  ('Jen','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "\n",
        "schema = StructType([StructField('name', StringType(), True),\n",
        "         StructField('dob', StringType(), True),\n",
        "         StructField('gender', StringType(), True),\n",
        "         StructField('salary', IntegerType(), True)\n",
        "         ])\n",
        "\n",
        "\n",
        "df = spark.createDataFrame(dataDF, schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9d194b45-9d22-4650-b7eb-228d6809818f",
          "showTitle": false,
          "title": ""
        },
        "id": "56dv8sWMcSAj"
      },
      "outputs": [],
      "source": [
        "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
        "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
        "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
        "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
        "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "structureSchema = StructType([\n",
        "        StructField('name', StructType([\n",
        "             StructField('firstname', StringType(), True),\n",
        "             StructField('middlename', StringType(), True),\n",
        "             StructField('lastname', StringType(), True)\n",
        "             ])),\n",
        "         StructField('id', StringType(), True),\n",
        "         StructField('gender', StringType(), True),\n",
        "         StructField('salary', IntegerType(), True)\n",
        "         ])\n",
        "\n",
        "df2 = spark.createDataFrame(dataDF,structureSchema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3933b037-3715-4af1-9c6d-3e68660af489",
          "showTitle": false,
          "title": ""
        },
        "id": "cA_GVXthdL3s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dhMREZkhAjke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9oWbvjFAjh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Casting\n",
        "from pyspark.sql.types import  StructType,  StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "df_schema = StructType(fields=[StructField(\"sr_no\", StringType(), False),\n",
        "                                StructField(\"name\", StringType(), True),\n",
        "                                StructField(\"age\", StringType(), True),\n",
        "                                StructField(\"fav_sport\", StringType(), True)])\n",
        "\n",
        "list = [\n",
        "  (1, 'Arul',23,'football'),\n",
        "  (2,'Sekar',34,'cricket'),\n",
        "  (3,'Vinoth',33,'chess'),\n",
        "  (4,'Ravi',30,'tennis')]\n",
        "\n",
        "df = spark.createDataFrame(list, df_schema)\n",
        "\n",
        "\n",
        "df.show()\n",
        "df.printSchema()\n",
        "#direct casting\n",
        "df_1= df.select(df.age.cast(\"int\"))\n",
        "#casting without alias\n",
        "df_2 = df.selectExpr('cast(age as INT)')\n",
        "#casting with alias\n",
        "df_3 = df.selectExpr('cast(age as INT) as new_age')\n",
        "#casting with new column as null\n",
        "df_4 = df.withColumn('new_age',lit(None))\n",
        "#casting with new column as null using selectExpr\n",
        "df_5 = df.selectExpr('cast(null as INT) as new_age')\n",
        "\n",
        "\n",
        "df_1.show()\n",
        "df_1.printSchema()\n",
        "df_2.show()\n",
        "df_2.printSchema()\n",
        "df_3.show()\n",
        "df_3.printSchema()\n",
        "df_4.show()\n",
        "df_4.printSchema()\n",
        "df_5.show()\n",
        "df_5.printSchema()"
      ],
      "metadata": {
        "id": "D6XqUX58Ajfj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {},
      "notebookName": "07_schema_control",
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "mount_file_id": "18-poI3ZmLoG-obz8rWMPZ2BBz69SzE-g",
      "authorship_tag": "ABX9TyMNc4ltrw0g2KPT2P2zMAsG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}