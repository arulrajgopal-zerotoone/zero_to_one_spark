{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arulrajgopal-zerotoone/zero_to_one_spark/blob/main/apache_spark/13_joins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "82ac370d-369e-4575-b056-39a226428ac3",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCF5-hhC5vLG",
        "outputId": "721cf207-ac6e-4e92-86a3-17054fdf2452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=e38dfaf3d6ff5ba85b145dcec37dd97d6f2e8b792b792f6ae086ffb32c072fa4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#create spark session\n",
        "spark= SparkSession.builder.appName('mysparksession').getOrCreate()\n",
        "\n",
        "#create spark context\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "6oFpwFolDIUR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6074db39-0623-4ca2-bd49-76090887a799",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOs1wzo_-dZL",
        "outputId": "02fdd85d-9015-4c8e-8c0f-e9656ebe93fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- emp_id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- superior_emp_id: long (nullable = true)\n",
            " |-- year_joined: string (nullable = true)\n",
            " |-- emp_dept_id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
            "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
        "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
        "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
        "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
        "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
        "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
        "  ]\n",
        "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
        "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
        "\n",
        "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
        "\n",
        "\n",
        "dept = [(\"Finance\",10), \\\n",
        "    (\"Marketing\",20), \\\n",
        "    (\"Sales\",30), \\\n",
        "    (\"IT\",40) \\\n",
        "  ]\n",
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
        "\n",
        "empDF.printSchema()\n",
        "deptDF.printSchema()\n",
        "empDF.show(truncate=False)\n",
        "deptDF.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spark joins\n",
        "1. inner\n",
        "2. outer, full, fullouter, full_outer\n",
        "3. left, leftouter, left_outer\n",
        "4. right, rightouter, right_outer\n",
        "5. anti, leftanti, left_anti\n",
        "6. semi, leftsemi, left_semi"
      ],
      "metadata": {
        "id": "jADrN9WwDSXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#inner"
      ],
      "metadata": {
        "id": "J1aaFKGaDTpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1e8d90c6-7cb9-4662-a6fa-9987ad8a7277",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20bni5YP-d_S",
        "outputId": "be4ea505-ca5b-4167-864f-e99a7f7ee43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#inner join\n",
        "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\") \\\n",
        "     .show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#outer"
      ],
      "metadata": {
        "id": "8vijmCvEDa2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1ad4180c-1634-465a-bda7-df3160187b8a",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eucg4I8-d9K",
        "outputId": "242cdcee-8885-4d43-88b7-05e98958d6e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|NULL  |NULL    |NULL           |NULL       |NULL       |NULL  |NULL  |Sales    |30     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "|6     |Brown   |2              |2010       |50         |      |-1    |NULL     |NULL   |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#outer\n",
        "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\")\\\n",
        "    .show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#right"
      ],
      "metadata": {
        "id": "Bm8t2MJVDeHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "076b5551-7371-42bb-9399-3c2431f8e0ef",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eng4Mx9-1zk",
        "outputId": "05aa1064-639f-44ab-9965-7f6a17799a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|NULL  |NULL    |NULL           |NULL       |NULL       |NULL  |NULL  |Sales    |30     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# right\n",
        "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\") \\\n",
        "   .show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#left"
      ],
      "metadata": {
        "id": "LOLoVL9RDfPB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "901ea8e9-4b28-4333-9eca-0df8a6561a54",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLOmHy1jD8vS",
        "outputId": "185a85a3-a6ce-4a60-f720-050791d32568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|6     |Brown   |2              |2010       |50         |      |-1    |NULL     |NULL   |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# left\n",
        "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\")\\\n",
        "    .show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#left anti & left semi"
      ],
      "metadata": {
        "id": "wblmE7MHDg_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "38e0f7c1-3d9b-4310-98d1-9c9d4736202d",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8_YkGN2EtOX",
        "outputId": "7e5ee31b-302a-4844-9c36-6c5713e526bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+---------------+-----------+-----------+------+------+\n",
            "|emp_id|name |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+-----+---------------+-----------+-----------+------+------+\n",
            "|6     |Brown|2              |2010       |50         |      |-1    |\n",
            "+------+-----+---------------+-----------+-----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# left\n",
        "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\")\\\n",
        "      .filter(col(\"dept_id\").isNull())\\\n",
        "      .drop(\"dept_name\",\"dept_id\")\\\n",
        "      .show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "25161825-b7a2-42a4-8d6b-4c15641b7464",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghnifo0LD51X",
        "outputId": "3ab753c8-f5d3-48f5-9aba-357016bd0bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+---------------+-----------+-----------+------+------+\n",
            "|emp_id|name |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+-----+---------------+-----------+-----------+------+------+\n",
            "|6     |Brown|2              |2010       |50         |      |-1    |\n",
            "+------+-----+---------------+-----------+-----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# left anti join\n",
        "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftanti\")\\\n",
        "   .show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "46b0abff-16cb-46c9-a331-27cef41f161f",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7MX2OMY-6CD",
        "outputId": "d06ad60b-d982-4003-ce3c-71845f5b75cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# left_semi\n",
        "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftsemi\")\\\n",
        "   .show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNfFB3JLDMqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWglYuGEDMmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bl-iaxt9DMjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WmGUbO2bDMe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvJyUF5gDMbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "64107023-9a21-47cb-a01e-8202fef03278",
          "showTitle": false,
          "title": ""
        },
        "id": "xERQA4z6_Bkf"
      },
      "outputs": [],
      "source": [
        "# join in multiple dataframes\n",
        "# f1.join(df2,df1.id1 == df2.id2,\"inner\") \\\n",
        "#    .join(df3,df1.id1 == df3.id3,\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6bd2a443-5889-4ea1-80db-b046d7e77f5a",
          "showTitle": false,
          "title": ""
        },
        "id": "26A7notf_Lkp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJQrI9aXCdnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Databricks notebook source\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC #Dataframe preparation\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "record_1 = [1,'A','arul','cricket']\n",
        "record_2 = [2,'A','sekar','chess']\n",
        "record_3 = [3,'A','kumar','tennis']\n",
        "record_4 = [1,'B', 'ganesh','football']\n",
        "record_5 = [2,'B','vinoth','volleyball']\n",
        "record_6 = [3,'B','Ravi','hockey']\n",
        "\n",
        "record_6 = [1, 'A','Engineer']\n",
        "record_7 = [2, 'A', 'doctor']\n",
        "record_8 = [2,'B', 'lawyer']\n",
        "\n",
        "list1 = [record_1, record_2, record_3,record_4,record_5]\n",
        "list2 = [record_6, record_7, record_8]\n",
        "\n",
        "df_schema = StructType(fields=[StructField(\"sr_no\", IntegerType(), False),\n",
        "                               StructField(\"section\", StringType(), False),\n",
        "                                StructField(\"name\", StringType(), True),\n",
        "                               StructField(\"fav_game\", StringType(), True)\n",
        "])\n",
        "\n",
        "df_2_schema = StructType(fields=[StructField(\"sr_no\", IntegerType(), False),\n",
        "                                 StructField(\"section\", StringType(), False),\n",
        "                                StructField(\"profession\", StringType(), True),\n",
        "])\n",
        "\n",
        "df = spark.createDataFrame(list1, df_schema)\n",
        "df_2 = spark.createDataFrame(list2, df_2_schema)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "df.show()\n",
        "df_2.show()\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC #Joining with Multiple condition\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "joined_df = df.alias('LH')\\\n",
        "                .join(df_2.alias('RH'), (col('LH.sr_no') == col('RH.sr_no')) & (col('LH.section') == col('RH.section')) , 'left')\\\n",
        "                .select('LH.*','RH.profession')\n",
        "\n",
        "joined_df.show()\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "joined_df.explain(True)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC #Broadcast join\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "large_df = df\n",
        "small_df = df_2\n",
        "\n",
        "result_df = large_df.alias(\"LH\").join(broadcast(small_df.alias(\"RH\")), (col('LH.sr_no') == col('RH.sr_no')) & (col('LH.section') == col('RH.section')), \"left\")\n",
        "result_df.display()\n",
        "# Note: - this is not large enough to broadcast, but for demo purpose, it has been done.\n",
        "\n",
        "result_df.explain(True)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC #Auto Broadcast\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# To disable autoBroadcastJoin >> set -1\n",
        "# By default it is 10485760 i.e. 10MB\n",
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
        "spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")"
      ],
      "metadata": {
        "id": "S-duaW8jCdk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Od-nLlICdiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uJTPX4WYCdf8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {},
      "notebookName": "09_joins",
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhyNnj/JiXj6vaPExOipNW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}